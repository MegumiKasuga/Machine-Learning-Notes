假设现在有一个线性回归模型，规定$d$为该模型的阶数。
需要知道的一点是：模型在训练集上工作得很好，并不等同于模型具有很好的泛化能力(即在训练集上工作得好不等于在新数据面前也工作得好)。

### 划分训练集、验证集与测试集
比如我们有三个不同的模型，它们分别为3阶，4阶，5阶；使用测试集的数据来对训练效果进行评价(算出每个模型的$J$函数值)。
假设我们选择了5阶的那个模型，如果我们使用它在测试集上的$J$来描述其泛化能力，这显然是不公平的，因为模型已经**对测试集有针对性地调整过了**，也就是说；我们的**测试集不再适合作为衡量一个模型泛化能力的指标**。
这时候就需要额外划分一个**验证集**，使用验证集来充当原来的测试集的作用，也就是说，在训练时使用测试集来在训练时提供$J$以修正模型，而在最终模型选择时，选则验证集提供的$J$来判断应当选择什么模型。(可以理解为测试集是模拟考，而验证集是最终的考试，通过验证集"考试"来给不同的模型打分。)
**一般来说，我们使用6:2:2的比例来分配训练集，验证集，测试集。**

### 诊断误差与方差
- **高方差、高误差：欠拟合**
	一般来说，欠拟合往往意味着模型的阶数不够，不能很好地反映训练集中样本的总体特征。
- **高方差、低误差：过拟合**
	过拟合往往意味着模型的阶数太高，能够很好地拟合训练集中的样本，
	但是在模型中加入了不属于训练集中数据的额外特征(一般是高次特征)。
	
- **诊断指标**
	如果是欠拟合问题，那么该模型在训练集和验证集上的$J$函数值都会高(也就是图像的左半部分)；如果是过拟合问题，那么该模型在训练集上的$J$会较低，而在验证集上的$J$较高(也就是图像的右半部分)
	![[Pasted image 20241228204200.png]]
- **正则化如何影响误差和方差**
	过大的$\lambda$会使得训练对所有参数取值的惩罚过大，最终会导致模型的阶数过低，导致欠拟合。
	而过小的$\lambda$会使得训练对参数取值的惩罚过小，导致模型的阶数过大，导致过拟合。
	在模型训练过程中，可以选择一系列不同的$\lambda$来获得不同阶数的模型，这样就可以在多个模型之间选择一个结果最好的。
	![[Pasted image 20241228205157.png]]
	$\lambda$的取值对于方差(验证集误差)和误差(训练集误差)的影响如上图，根据该图可知，$\lambda$太小就可能导致过拟合，$\lambda$太大就可能导致欠拟合。

### 学习曲线
学习曲线是一种评估模型学习效果的方法，它能够很好地判断模型处于哪一种状态(欠拟合？正好？过拟合？)
![[Pasted image 20241228210544.png]]
随着训练样本量的增加，模型在训练集和验证集上的误差会逐渐趋于同一个值。
![[Pasted image 20241228210808.png]]
当模型处于高误差状态时，训练集误差和验证集误差会**接近得很快**，并且最终逼近的**误差值会偏高**。
![[Pasted image 20241228211057.png]]
当模型处于高方差状态时，训练集误差会始终处于一个较小的状态，而验证集误差始终偏大，它们之间始终**保持一个较大的鸿沟**。

#### 基于迭代次数的学习曲线
如果一个模型处于欠拟合状态，那么它的学习曲线就会是下面这个样子：
(线性回归模型)
![[Pasted image 20241228211917.png]]
(逻辑回归模型)
![[Pasted image 20241228211944.png]]
而如果一个模型处于过拟合状态，那么它的学习曲线就会是下面这个样子：
(线性回归模型)
![[Pasted image 20241228212050.png]]
(逻辑回归模型)
![[Pasted image 20241228212114.png]]
### 模型的调试
- **若要修正模型的高方差**
	- 获取更多训练样本
	- 减小特征数量
	- 增大正则化$\lambda$
- **若要修正模型的高误差**
	- 增大特征数量
	- 增大多项式特征数量(使用高阶特征，如高次项)
	- 减小正则化$\lambda$



