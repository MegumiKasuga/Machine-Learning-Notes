**泛化(Genrealizing)**：泛化能力是描述机器学习算法的重要指标，其描述模型在处理新数据(即来自训练集之外的数据)，取得正确结果的能力。
### 欠拟合(Underfitting)
指的是模型不能很好地拟合给定的数据集，或者说该模型具有高偏差(high bias)。如图就是一种欠拟合的情况。（模型的阶数低于数据集的阶数）
![[Pasted image 20241227212543.png]]

### 过拟合(Overfitting)
指的是模型的虽然能够很好地拟合给定的数据集，但却不能很好地反映数据集的总体趋势，对于训练集外的数据不能很好地预测，也可以说该模型具有高方差(high variance)。如图就是一种过拟合的情况。（模型的阶数高于数据集的阶数）
![[Pasted image 20241227212827.png]]

对于过拟合和欠拟合两种情况来说，模型的**泛化能力都会下降**，在模型"恰恰正好"时，模型的泛化能力就(应当)是最强的。他们的区别在于，
	在欠拟合情况下，模型即使对于训练集种已有的数据，其预测准确性也很低；
	在过拟合情况下，模型对于已知数据工作得很好。

### 处理过拟合的一些方法
1. **减少特征的数量**
	- 人工选择保留哪些特征。
	- 使用模型选择算法。
2. **正则化(Regularization)**
	- 保留所有参数，但减少对应参数的数量级或值。
	- 即使在我们有大量的参数，并且我们需要其中的每个参数时仍能很好地工作。

## 正则化
### 正则化的目的是什么
正则化的主要目的在于，**我们需要一个“最简”的$h$函数**，**并且我们需要更不容易过拟合的模型**。因此，对于一些值非常小的参数(一般来说是高阶参数)，那么这时候可以尝试“修剪”掉这些参数(即使得对应的$\theta$为0)，或者通过给予惩罚，强迫我们的算法去减小这些参数的取值。比如，对于这样的一个$h$函数：$$h_{\theta}(x)=\theta_{0} + \theta_{1}x + \theta_{2}x^2 + \theta_{3}x^4$$我们可以通过对$J(\theta)$做这样的修改(仅仅作为一个例子)，给$\theta_{3}$和$\theta_{4}$加入惩罚：$$J(\theta) = \frac{1}{2m}\sum_{i=1}^m(h_{\theta}(x^{(i)}) - y^{(i)})^2 + 1000\theta_{3}^2 + 1000\theta_{4}^2$$
在这个代价函数中，我们就强迫我们的算法找到使得这两个参数尽可能小的拟合函数，因为这两个参数的大小也将被记为损失的一部分。

### 正则化要做什么
因此，**正则化的任务就是**：修改代价函数$J(\theta)$，**使得这个代价函数能够缩小所有的参数的取值**(这里我们需要思考的是："修剪"掉我们不需要的参数这个命题是否现实?我们真的能够预先知道哪些参数是我们不需要的吗?如果不能，那么直接将所有参数的值都作为惩罚项就是最好的)。
也就是说，当一个模型经过正则化之后，它不仅要能够取得最好的模型表现，且它所有的参数取值(当然，指的是绝对值)之和应当是最小的。

### 正则化的$J$代价函数
我们的解决办法很简单，函数形式如下：$$J(\theta) = \frac{1}{2m}\sum_{i=1}^m(h_{\theta}(x^{(i)}) - y^{(i)})^2 + \lambda\sum_{i=1}^m\theta_{j}^2$$这个函数将所有的参数的绝对大小都作为惩罚项的一部分，那么就能强迫我们的算法取得一个所有参数值的和相对最小的解矢量。

##### 参数$\lambda$
这里的参数$\lambda$的取值就是在这两个目标之间进行取舍，防止过拟合和更好地拟合数据之间往往不能"既要又要"，因此我们必须在这两个目标之间作出取舍，如果我们需要更好的拟合效果，那么我们就需要更小的$\lambda$，但这同时也意味着我们的算法抵抗过拟合的效果不好。反之，我们的拟合效果可能没那么好，但也不那么容易过拟合。
如果参数$\lambda$给得太大，那么意味着我们对$\theta$的任何取值都给予一个过大的惩罚，这样我们的模型就可能会进入欠拟合状态，因此我们对$\lambda$的取值应当处在一个合理的范围。

### 线性回归的正则化
对于梯度下降法，我们需要做的是，将梯度下降函数修改为如下形式：$$\theta_{j}~:=~\theta_{j}-\alpha\frac{1}{m}\sum_{i=1}^m(h_{\theta}(x^{(i)})-y^{(i)})x^{(i)}_{j} + \frac{\lambda}{m}\theta_{j}$$
对于正规方程法，将正规方程修改为如下形式：$$\theta =\left(X^TX + \lambda\left[\begin{array} \\
0 &&& \\
&1&& \\
&&\dots& \\
&&&1 \\
\end{array}\right]\right)^{-1}X^Ty$$

### 逻辑回归的正则化
道理和线性回归的正则化是类似的，我们需要在$J(\theta)$代价函数当中增加一个$\theta$的惩罚项。对于梯度下降法，我们可以这么做：$$J(\theta)=-\left[\frac{1}{m}\sum_{i=1}^my^{(i)}\log h_{\theta}(x^{(i)}) + (1-y^{(i)})\log(1-h_{\theta}(x^{(i)}))\right] + \frac{\lambda}{2m}\sum_{j=1}^n\theta_{j}^2$$也就是说，我们可以在原本的$J(\theta)$之后给所有$\theta$额外加上一个惩罚项。
而对于操作过程，进行如下修改：
重复 {
$$\theta_{0}:=\theta_{0}-\alpha \frac{1}{m} \sum_{i=1}^m (h_{\theta}(x^{(i)})-y^{(i)})x_{0}^{(i)}$$$$\theta_{j}:=\theta_{j}-\alpha \frac{1}{m} \sum_{i=1}^m (h_{\theta}(x^{(i)})-y^{(i)}_{j})x_{j}^{(i)} + \frac{\lambda}{m}\theta_{j}~~~,~~~j=1,2,\dots,n$$
}直至收敛。