Softmax分类器是对逻辑回归的一种专精于多分类的扩展，当分类数量为2时，其将退化为逻辑回归。

### Softmax函数
假设又一个数组$V$，其中有$n$个元素，$V_{i}$表示数组中的第$i$个元素，那么这个元素的softmax值为：$$S_{i}=\frac{e^i}{\sum_{j=1}^ne^j}$$即该元素的指数与所有元素指数和的比值。
这么定义的目的在于：
- 希望特征对概率的影响是乘性的
- 多分类问题的目标函数常常使用交叉熵代价函数，即$L=-\sum_{k}t_{k}\cdot \ln(P(y=k))$，其中目标类的$t_{k}$为1，其余类的$t_{k}$为0。

### $J$代价函数
上文已经提到$$J(\theta)=-\sum_{i=1}^m t_{i}\ln(y_{i})$$那么我们就可以知道：$Cost(\theta)_{i}=-\ln y_{i}$
对$J(\theta)$求导，根据前述定义:$$y_{i}=\frac{e^i}{\sum_{j}e^j}$$那么就有：$$\frac{e^i}{\sum_{j}e^j}=1-\frac{\sum_{j \neq i}e^j}{\sum_{j}e^j}$$最终可以求得偏导数：$$\frac{\partial}{\partial\theta_{i}}J(\theta)=y_{i}-1$$根据这个结果，我们只需要正向求出$y_{i}$，将结果减去1就是反向更新的梯度。

