### 偏斜类/不对称类
指的是一个类的样本数量远远大于另一个类，比如一个数据集中有99%的数据属于类A，只有1%的数据属于类B。那么这就是一组不对称类。
对于这种不对称类，如果直接使用准确率/错误率来作为评估指标就是不合适的，因为我们并没有区分错误是什么类型的错误，究竟是错误地将A样本分为B类还是反之？这显然是重要的。
#### 分类结果的四种情况
假设我们在进行一个二分类任务，设定A类为阳性类，B类为阴性类。
- 真阳性：样本属于A类，分类结果为A类(TP)。分类正确。
- 假阳性：样本属于B类，分类结果为A类(FP)。分类错误。
- 真阴性：样本属于B类，分类结果为B类(TN)。分类正确。
- 假阴性：样本属于A类，分类结果为B类(FN)。分类错误。

#### 四个"率"
- 真阳性率：$TPR=\frac{TP}{P}$
- 假阳性率：$FPR=\frac{FP}{N}$
- 真阴性率：$TNR=\frac{TN}{N}=1-FPR$
- 假阴性率：$FNR=\frac{FN}{P}=1-TPR$

### 查准率，召回率与$F_{1}$值
查准率的值即为真阳性的数量除以所有分类结果为阳性的样本的数量，即：$$Precision=\frac{TP}{TP+FP}$$
召回率即为真阳性的数量除以所有实际上为阳性的样本的数量，即：$$Recall=\frac{TP}{TP+FN}$$
如果某个模型的查准率和召回率都比较高，我们就可以说该模型工作得比较好。
**F值**
F值是非常重要的计算模型工作效率的手段。它的公式如下：$$F_{\beta}=(1+\beta^2)\frac{Precision \cdot recall}{\beta^2 \cdot presicion + recall}$$一般情况下，我们只会用到$\beta=1$的时候的该值，也即$F_{1}$值。
$F_{1}$值的计算公式如下：$$F_{1}=2\frac{Presicion \cdot Recall}{Presicion+\mathrm{Re}call}$$$F_{1} \in [0,1]$，只有在查准率与召回率都高的时候，$F_{1}$值才会大。
如果我们需要一个查全率和查准率都高的模型，考察$F_{1}$值就是比较合理的。
反之，如果我们只需要其中一个值比较大的模型，那么直接考察该值即可。

### ROC曲线与AUC
ROC曲线是多个混淆矩阵的结果组合。假设在某模型中我们没有事先设定好阈值，而是将模型预测结果从高到低排序，将每个概率值作为阈值，那么就会有多个混淆矩阵。对每个矩阵，我们计算$TPR$和$FPR$，$TPR$同时等于我们的召回率Recall。FPR即为实际为阴性的样本被预测为阳性的概率。以FPR为x轴，TPR为y轴画图，得到ROC曲线，如下图。
![[Pasted image 20241230220044.png]]
AUC即为ROC曲线下方的面积，这个面积若等于0.5，那么可以认为该模型和纯猜没什么区别，一般来说AOC越大，我们可以认为该模型的预测效果越好；同时ROC越光滑，就代表着模型过拟合的可能性越小；反之，模型过拟合的可能性越大(比如0.2-0.4这一段就可能由过拟合问题存在)。

### PRC曲线
PRC曲线，即查准率、召回率曲线，和ROC类似，PRC曲线是FPR和TPR的点连城的线。对于PRC而言，线条平滑、线下面积大的比较好。一般来说，我们期望中的好模型应当拥有一个大mAP(蓝色线下面积要大)。
对于PRC曲线而言，线下面积大，就意味着真阳性率高、召回率高，而假阳性率、假阴性率低，也就意味着我们的模型表现好。
![[Pasted image 20241230220635.png]]
